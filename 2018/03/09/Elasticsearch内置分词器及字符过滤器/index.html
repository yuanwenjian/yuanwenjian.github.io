<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">
<meta name="google-site-verification" content="mtcPxgu7dngx94l_3Lo41vqUNQxHgj7vMtg7LSQvKvU" />


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="elasticsearch," />










<meta name="description" content="分词器接收到一串字符，将其分解为单独的词语（通常是单个单词），并输出词语流。例如，空白分词器每当看到任何空格时，将文本分解成词语。它将文本&quot;Quick brown fox&quot; 转换为词语[Quick,brown,fox!]。分词器还负责记录每个词语的顺序或位置以及体现词语的原始单词开始和结束字符偏移量。词语过滤器接收词语流，并可以添加，删除和修改词语。例如，小写词语过滤器将所有词语转换为小写，停止词">
<meta name="keywords" content="elasticsearch">
<meta property="og:type" content="article">
<meta property="og:title" content="Elasticsearch内置分词器及字符过滤器">
<meta property="og:url" content="http://yoursite.com/2018/03/09/Elasticsearch内置分词器及字符过滤器/index.html">
<meta property="og:site_name" content="问问苑大宝">
<meta property="og:description" content="分词器接收到一串字符，将其分解为单独的词语（通常是单个单词），并输出词语流。例如，空白分词器每当看到任何空格时，将文本分解成词语。它将文本&quot;Quick brown fox&quot; 转换为词语[Quick,brown,fox!]。分词器还负责记录每个词语的顺序或位置以及体现词语的原始单词开始和结束字符偏移量。词语过滤器接收词语流，并可以添加，删除和修改词语。例如，小写词语过滤器将所有词语转换为小写，停止词">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-07-15T05:45:04.687Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Elasticsearch内置分词器及字符过滤器">
<meta name="twitter:description" content="分词器接收到一串字符，将其分解为单独的词语（通常是单个单词），并输出词语流。例如，空白分词器每当看到任何空格时，将文本分解成词语。它将文本&quot;Quick brown fox&quot; 转换为词语[Quick,brown,fox!]。分词器还负责记录每个词语的顺序或位置以及体现词语的原始单词开始和结束字符偏移量。词语过滤器接收词语流，并可以添加，删除和修改词语。例如，小写词语过滤器将所有词语转换为小写，停止词">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/03/09/Elasticsearch内置分词器及字符过滤器/"/>





  <title>Elasticsearch内置分词器及字符过滤器 | 问问苑大宝</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	<a href="https://github.com/yuanwenjian" target="_blank"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/e7bbb0521b397edbd5fe43e7f760759336b5e05f/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677265656e5f3030373230302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_green_007200.png"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">问问苑大宝</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/09/Elasticsearch内置分词器及字符过滤器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="问问苑大宝">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/sanguosha.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="问问苑大宝">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Elasticsearch内置分词器及字符过滤器</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-09T20:40:00+08:00">
                2018-03-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/" itemprop="url" rel="index">
                    <span itemprop="name">elasticsearch</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/elasticsearch/后端/" itemprop="url" rel="index">
                    <span itemprop="name">后端</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/03/09/Elasticsearch内置分词器及字符过滤器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/2018/03/09/Elasticsearch内置分词器及字符过滤器/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          
              <div class="post-description">
                  分词器接收到一串字符，将其分解为单独的词语（通常是单个单词），并输出词语流。例如，空白分词器每当看到任何空格时，将文本分解成词语。它将文本"Quick brown fox" 转换为词语[Quick,brown,fox!]。分词器还负责记录每个词语的顺序或位置以及体现词语的原始单词开始和结束字符偏移量。词语过滤器接收词语流，并可以添加，删除和修改词语。例如，小写词语过滤器将所有词语转换为小写，停止词语过滤器会从词语流中删除常用字（停止字），同义词词语过滤器会将同义词引入到词语流中。词语过滤器不允许改变每个词语的位置或字符偏移量。
              </div>
          

          
        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h1><h2 id="Character-filter-字符过滤器"><a href="#Character-filter-字符过滤器" class="headerlink" title="Character filter(字符过滤器)"></a>Character filter(字符过滤器)</h2><p>char_filter 字符过滤器接收原始文本作为字符流，并可以通过添加、删除和更改字符来转换流。例如，可以使用字符过滤器将印度-阿拉伯数字（0123456789）转换成阿拉伯-拉丁语中的（0123456789），或从流中剥离HTML元素。<br>分析器可能有零个或多个字符过滤器，它们会按顺序应用。</p>
<h2 id="Tokenizer-分词器"><a href="#Tokenizer-分词器" class="headerlink" title="Tokenizer(分词器)"></a>Tokenizer(分词器)</h2><p>tokenizer 分词器接收到一串字符，将其分解为单独的词语（通常是单个单词），并输出词语流。例如，空白分词器每当看到任何空格时，将文本分解成词语。它将文本”Quick brown fox” 转换为词语[Quick,brown,fox!]。<br>分词器还负责记录每个词语的顺序或位置以及体现词语的原始单词开始和结束字符偏移量。<br>分析器必须只有一个分词器。</p>
<h2 id="Token-filter-Token-过滤器"><a href="#Token-filter-Token-过滤器" class="headerlink" title="Token filter(Token 过滤器)"></a>Token filter(Token 过滤器)</h2><p>filter 词语过滤器接收词语流，并可以添加，删除和修改词语。例如，小写词语过滤器将所有词语转换为小写，停止词语过滤器会从词语流中删除常用字（停止字），同义词词语过滤器会将同义词引入到词语流中。<br>词语过滤器不允许改变每个词语的位置或字符偏移量。<br>分析器可以具有零个或多个词语过滤器，它们会按顺序应用。</p>
<h2 id="Analyzer-分析器"><a href="#Analyzer-分析器" class="headerlink" title="Analyzer(分析器)"></a>Analyzer(分析器)</h2><p>分析器（无论是内置还是自定义）只是一个包含三个较底层组件的包：字符过滤器，分词器，和令牌过滤器。<br>内置分析器将这些组件预先封装成适用于不同语言和文本类型的分析器。Elasticsearch还暴露了各个组件，以便它们可以组合起来定义新的定制分析器。<br>分析器流程如下</p>
<ol>
<li>首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将 &amp; 转化成 <code>and</code>。</li>
<li>然后字符串被 分词器 分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。</li>
<li>最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化 Quick ），删除词条（例如， 像 a<code>，</code>and<code>，</code>the 等无用词），或者增加词条（例如，像 jump 和 leap 这种同义词）。<h2 id="Token-词元"><a href="#Token-词元" class="headerlink" title="Token(词元)"></a>Token(词元)</h2>文档通过Tokenizer 生成Token</li>
</ol>
<h2 id="Term"><a href="#Term" class="headerlink" title="Term"></a>Term</h2><p>被分析器处理后的结果为Term</p>
<h2 id="Frequency-词频"><a href="#Frequency-词频" class="headerlink" title="Frequency(词频)"></a>Frequency(词频)</h2><p>文档中包含几个 Term成为Frequency</p>
<h1 id="es内置-Character-filter"><a href="#es内置-Character-filter" class="headerlink" title="es内置 Character filter"></a>es内置 Character filter</h1><table>
<thead>
<tr>
<th>过滤器</th>
<th>简称</th>
<th>描述</th>
<th>支持参数</th>
</tr>
</thead>
<tbody>
<tr>
<td>HTML Strip Char Filter</td>
<td>html_strip</td>
<td>去除HTML元素</td>
<td>escaped_tags(排除的标签数组)</td>
</tr>
<tr>
<td>Mapping Char Filter</td>
<td>mapping</td>
<td>根据配置的映射配置</td>
<td>mappings_path(一个key =&gt; value特定格式的文件路径,相对或config文件夹)</td>
</tr>
<tr>
<td>Pattern Replace Char Filter</td>
<td>pattern_replace</td>
<td>使用java正则替换</td>
<td>pattern,replacement,flags</td>
</tr>
</tbody>
</table>
<h1 id="es内置tokenizer"><a href="#es内置tokenizer" class="headerlink" title="es内置tokenizer"></a>es内置tokenizer</h1><h2 id="Standard-Tokenizer"><a href="#Standard-Tokenizer" class="headerlink" title="Standard Tokenizer"></a>Standard Tokenizer</h2><ol>
<li><strong>描述</strong>:<br>标准分析器是Elasticsearch默认使用的分析器。它是分析各种语言文本最常用的选择。它根据 Unicode 联盟 定义的 单词边界 划分文本。删除绝大部分标点</li>
<li><strong>简称</strong>: standard</li>
<li><strong>参数</strong>: max_token_length //拆分token最大长度,如果超多最大限度使用max_token_length间隔进行拆分,默认为255</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;standard&quot;,</span><br><span class="line">          &quot;max_token_length&quot;: 5</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_index/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;my_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;The 2 QUICKED Brown-Foxes jumped over the lazy dog&apos;s bone.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ The, 2, QUICK, ED, Brown, Foxes, jumpe, d, over, the, lazy, dog&apos;s, bone ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Letter-Tokenizer"><a href="#Letter-Tokenizer" class="headerlink" title="Letter Tokenizer"></a>Letter Tokenizer</h2><ol>
<li><strong>描述</strong>: 字母标记器只要遇到不是字母的字符就会将文本分解为字词。对于大多数欧洲语言该分词是合理的,但一部分亚洲语言不是使用空格分隔,使用该分词器效果很不友好</li>
<li><strong>简称</strong>: letter</li>
<li><strong>参数</strong>: 无</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokenizer&quot;: &quot;letter&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;The 2 QU3ICK Brown-Foxes jumped over the lazy dog&apos;s bone.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ The, QU, ICK, Brown, Foxes, jumped, over, the, lazy, dog, s, bone ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Lowercase-Tokenizer"><a href="#Lowercase-Tokenizer" class="headerlink" title="Lowercase Tokenizer"></a>Lowercase Tokenizer</h2><ol>
<li><strong>描述</strong>: 与Letter Tokenizer类似,遇到非字母时将文档拆分为token,并且转为小写,功能与letter tokenizer与lowercase filter组合一样,但是效率更高</li>
<li><strong>简称</strong>: lowercase</li>
<li><strong>参数</strong>: 无</li>
<li><strong>示例</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokenizer&quot;: &quot;lowercase&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;The 2 QU6ICK Brown-Foxes jumped over the lazy dog&apos;s bone.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ the, qu, ick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Whitespace-Tokenizer"><a href="#Whitespace-Tokenizer" class="headerlink" title="Whitespace Tokenizer"></a>Whitespace Tokenizer</h2><ol>
<li><strong>描述</strong>: 通过空格将文本拆分为token</li>
<li><strong>简称</strong>: whitespace</li>
<li><strong>参数</strong>: 无</li>
<li><strong>示例</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokenizer&quot;: &quot;whitespace&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;The 2 QUICK... Brown-Foxes jumped over the lazy dog&apos;s bone.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ The, 2, QUICK..., Brown-Foxes, jumped, over, the, lazy, dog&apos;s, bone. ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p><font color="red">5. <strong>注意</strong>: </font>拆分token最大长度为255,如果文本超过255,将被分割为255字符</p>
<h2 id="UAX-URL-Email-Tokenizer"><a href="#UAX-URL-Email-Tokenizer" class="headerlink" title="UAX URL Email Tokenizer"></a>UAX URL Email Tokenizer</h2><ol>
<li><strong>描述</strong>: uax_url_email分词器与标准分词器类似,只是它将url与email单独处理</li>
<li><strong>简称</strong>: uax_url_email</li>
<li><strong>参数</strong>: max_token_length  默认为255</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;uax_url_email&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">POST my_index/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;my_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;My Email is john.smith@global-international.com&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">[My,  Email , is , john.smith@global-international.com]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Classic-Tokenizer"><a href="#Classic-Tokenizer" class="headerlink" title="Classic Tokenizer"></a>Classic Tokenizer</h2><ol>
<li><strong>描述</strong>: classic基于语法的tokenizer,适用于英文文档,该分词器对首字母缩略词，公司名称，电子邮件地址和互联网主机名称进行特殊处理具有启发式的作用。但是，这些规则并不总是有效，除英语以外的语言，该分词器大多数不起作用<ul>
<li>它以大多数标点符号分割字词，删除标点符号。 不过，后面没有空格的点被认为是 token 的一部分。</li>
<li>它以连字符分隔单词。除非 token 中有一个数字，在这种情况下，整个 token 将被解释为产品编号，并且不分割。</li>
<li>它将电子邮件地址和互联网主机名识别为一个词元。</li>
</ul>
</li>
<li><strong>简称</strong>:  classic</li>
<li><strong>参数</strong>: max_token_length</li>
<li><p><strong>示例</strong>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;classic&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;The 2 QUICK Brown-Foxes 3 jumped over the lazy dog&apos;s bone 3-other t. t.o www@baidu.com  tue@&quot;</span><br><span class="line">&#125;</span><br><span class="line">输出结果</span><br><span class="line">[The , 2,  QUICK ,Brown,Foxes, 3 , jumped, over, the, lazy ,dog, bone, 3-other , t , t.o ,www@baidu.com , tue]</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>说明</strong></p>
</li>
</ol>
<ul>
<li>t与t.o <del>对应后面没有空格的点被认为是 token 的一部分</del>。</li>
<li>3-other未拆分,Brown-Foxes拆分 对应<del>token 中有一个数字，在这种情况下，整个 token 将被解释为产品编号，并且不分割</del></li>
<li>www@baidu.com , tue对比 对应<del>将电子邮件地址和互联网主机名识别为一个词元</del><h2 id="Thai-Tokenizer"><a href="#Thai-Tokenizer" class="headerlink" title="Thai Tokenizer"></a>Thai Tokenizer</h2></li>
</ul>
<ol>
<li><strong>描述</strong> :泰语分词器</li>
<li><strong>简称</strong>: thai</li>
<li><strong>参数</strong>: 无<h2 id="NGram-Tokenizer"><a href="#NGram-Tokenizer" class="headerlink" title="NGram Tokenizer"></a>NGram Tokenizer</h2></li>
<li><strong>描述</strong>:遇到指定字符列表中的某一个时，它首先将文本分解为单词,然后返回指定长度的N-Gram,N-grams 就像一个滑动窗口在单词上移动，是一个连续的指定长度的字符序列,通常用于不使用空格或长复合词的语言,比如德语</li>
<li><strong>简称</strong>: ngram</li>
<li><strong>参数</strong>:<ul>
<li>min_gram gram最小长度,默认为1</li>
<li>max_gram gram最大长度,默认为2</li>
<li>token_chars 应包含在词元中的字符类。 Elasticsearch将分割不属于指定类的字符。 默认为[]（保留所有字符）,字符类可能是以下任何一种：<br>(需要处理的字符类)<ul>
<li>letter  如:a, b, ï or 京</li>
<li>digit     如:3 or 7</li>
<li>whitespace  如: “ “ or “\n”</li>
<li>punctuation   如: ! or “</li>
<li>symbol    如:$ or √</li>
</ul>
</li>
<li>提示: 通常将min_gram与max_gram设为一样的值,值越小，匹配到的文档越多，但是匹配的质量越差。值越大，越能匹配到指定的文档。 3 是一个不错的初始值。    </li>
</ul>
</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;ngram&quot;,</span><br><span class="line">          &quot;min_gram&quot;: 1,</span><br><span class="line">          &quot;max_gram&quot;: 3,</span><br><span class="line">          &quot;token_chars&quot;: [</span><br><span class="line">            &quot;letter&quot;,</span><br><span class="line">            &quot;digit&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_index/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;my_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 Quick Foxes.&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ Qui, uic, ick, Fox, oxe, xes ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Edge-NGram-Tokenizer"><a href="#Edge-NGram-Tokenizer" class="headerlink" title="Edge NGram Tokenizer"></a>Edge NGram Tokenizer</h2><ol>
<li><p><strong>描述</strong>: 当遇到指定字符列表中的一个时，edge_ngram标记器首先将文本分解成单词,然后返回指定长度的每个单词的 N-grams,其中gram的开始处是单词的开始处</p>
<ul>
<li>当你搜索的类型具有广为人知的顺序,建议搜索使用edge_ngram比ngram更高效,尝试自动填充可能以任何顺序出现的单词时ngram效率更高</li>
</ul>
</li>
<li><strong>简称</strong>: edge_ngram</li>
<li><strong>参数</strong> 与ngram参数相同</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;edge_ngram&quot;,</span><br><span class="line">          &quot;min_gram&quot;: 2,</span><br><span class="line">          &quot;max_gram&quot;: 10,</span><br><span class="line">          &quot;token_chars&quot;: [</span><br><span class="line">            &quot;letter&quot;,</span><br><span class="line">            &quot;digit&quot;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_index/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;my_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;2 Quick Foxes.&quot;</span><br><span class="line">&#125;</span><br><span class="line">输出结果</span><br><span class="line">[ Qu, Qui, Quic, Quick, Fo, Fox, Foxe, Foxes ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Keyword-Tokenizer"><a href="#Keyword-Tokenizer" class="headerlink" title="Keyword Tokenizer"></a>Keyword Tokenizer</h2><ol>
<li><strong>描述</strong>:一个“noop”标记器,将整个输入完整一样输出</li>
<li><strong>简称</strong>: keyword</li>
<li><strong>参数</strong>:<ul>
<li>buffer_size 一次读入术语缓冲区的字符数。默认为256.术语缓冲区将按此大小增长，直到所有文本被消耗完。建议不要更改此设置。</li>
</ul>
</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;tokenizer&quot;: &quot;keyword&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;New York&quot;</span><br><span class="line">&#125;</span><br><span class="line">输出结果</span><br><span class="line">[ New York ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Pattern-Tokenizer"><a href="#Pattern-Tokenizer" class="headerlink" title="Pattern Tokenizer"></a>Pattern Tokenizer</h2><ol>
<li><strong>描述</strong>: 使用正则表达式将文本拆分为与分词匹配的词条，或者将匹配的文本作为词条捕获</li>
<li><strong>简称</strong>: pattern</li>
<li><strong>参数</strong>:<ul>
<li>pattern</li>
<li>flag</li>
<li>group</li>
</ul>
</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;pattern&quot;,</span><br><span class="line">          &quot;pattern&quot;: &quot;,&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ comma, separated, values ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Simple-Pattern-Tokenizer"><a href="#Simple-Pattern-Tokenizer" class="headerlink" title="Simple Pattern Tokenizer"></a>Simple Pattern Tokenizer</h2><ol>
<li><strong>描述</strong>:使用正则表达式来捕获匹配的文本作为术语。它支持的一组正则表达式特征比pattern更有限，通常更快。<br>默认模式是空字符串，它不会生成任何术语。该标记器应始终配置为非默认模式。</li>
<li><strong>简称</strong>: simple_pattern</li>
<li><strong>参数</strong>: pattern 默认为空</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;simple_pattern&quot;,</span><br><span class="line">          &quot;pattern&quot;: &quot;[0123456789]&#123;3&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_index/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;my_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;fd-786-335-514-x&quot;</span><br><span class="line">&#125;</span><br><span class="line">输出结果</span><br><span class="line">[ 786, 335, 514 ]</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Simple-Pattern-Split-Tokenizer"><a href="#Simple-Pattern-Split-Tokenizer" class="headerlink" title="Simple Pattern Split Tokenizer"></a>Simple Pattern Split Tokenizer</h2><ol>
<li><strong>描述</strong>: 按照正则指定拆分输入文本,支持的正则表达式比pattern少,但是速度更快</li>
<li><strong>简称</strong>:simple_pattern_split</li>
<li><strong>参数</strong>:pattern</li>
<li><strong>示例</strong>:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;analysis&quot;: &#123;</span><br><span class="line">      &quot;analyzer&quot;: &#123;</span><br><span class="line">        &quot;my_analyzer&quot;: &#123;</span><br><span class="line">          &quot;tokenizer&quot;: &quot;my_tokenizer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;my_tokenizer&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;simple_pattern_split&quot;,</span><br><span class="line">          &quot;pattern&quot;: &quot;_&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_index/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  &quot;analyzer&quot;: &quot;my_analyzer&quot;,</span><br><span class="line">  &quot;text&quot;: &quot;an_underscored_phrase&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">输出结果</span><br><span class="line">[ an, underscored, phrase ]</span><br><span class="line">``` </span><br><span class="line">## Path Hierarchy Tokenizer</span><br><span class="line">1. **描述**: 把分层的值看成是文件路径，用路径分隔符分割文本，输出树上的各个节点。</span><br><span class="line">2. **简称**: path_hierarchy</span><br><span class="line">3. **参数**:</span><br><span class="line">    - delimiter: 路径分隔符。默认是 / 。</span><br><span class="line">    - replacement: 路径分隔符的替换字符。默认是 delimiter.</span><br><span class="line">    - buffer_size: 一次读到词元缓冲区的字符数。默认是 1024 。 词元缓冲区以此大小增长，只到读完所有的文本。建议不要更改这项配置。</span><br><span class="line">    - reverse: 若为 true ，以相反的顺序发射词元。默认是 false 。</span><br><span class="line">    - skip:忽视的原始词元的数量。默认是0</span><br><span class="line">4. **示例**:</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>PUT my_index<br>{<br>  “settings”: {<br>    “analysis”: {<br>      “analyzer”: {<br>        “my_analyzer”: {<br>          “tokenizer”: “my_tokenizer”<br>        }<br>      },<br>      “tokenizer”: {<br>        “my_tokenizer”: {<br>          “type”: “path_hierarchy”,<br>          “delimiter”: “-“,<br>          “replacement”: “/“,<br>          “skip”: 2<br>        }<br>      }<br>    }<br>  }<br>}</p>
<p>POST my_index/_analyze<br>{<br>  “analyzer”: “my_analyzer”,<br>  “text”: “one-two-three-four-five”<br>}<br>输出结果<br>[ /three, /three/four, /three/four/five ]<br>如果reverse为true,结果为:<br>[ one/two/three/, two/three/, three/ ]<br>``` </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/elasticsearch/" rel="tag"><i class="fa fa-tag"></i> elasticsearch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/08/Chrome无法打开AXURE插件/" rel="next" title="Chrome无法打开AXURE插件解决办法">
                <i class="fa fa-chevron-left"></i> Chrome无法打开AXURE插件解决办法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/03/10/Elasticsearch内置分析器/" rel="prev" title="Elasticsearch内置分析器">
                Elasticsearch内置分析器 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
  <div onclick="showGitment()" id="gitment_title" class="gitment_title">显示 Gitment 评论</div>
  <div id="container" style="display:none"></div>
  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
  <script>
  const myTheme = {
    render(state, instance) {
      const container = document.createElement('div');
      container.lang = "en-US";
      container.className = 'gitment-container gitment-root-container';
      container.appendChild(instance.renderHeader(state, instance));
      container.appendChild(instance.renderEditor(state, instance));
      container.appendChild(instance.renderComments(state, instance));
      container.appendChild(instance.renderFooter(state, instance));
      return container;
    }
  }
  function showGitment() {
    $("#gitment_title").attr("style", "display:none");
    $("#container").attr("style", "").addClass("gitment_container");
    var gitment = new Gitment({
      id: 'Elasticsearch内置分词器及字符过滤器',
      theme: myTheme,
      owner: "yuanwenjian",
      repo: "gitment-comments",
      oauth: {
        client_id: '21bb0ade50d6f2c9707b',
        client_secret: '903e69fae75a4c67e11677d996fbf77c4a6f0639'
      }
    });
    gitment.render('container');
  }
  </script>


  


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/sanguosha.jpg"
                alt="问问苑大宝" />
            
              <p class="site-author-name" itemprop="name">问问苑大宝</p>
              <p class="site-description motion-element" itemprop="description">策谋本天成，妙手偶得之</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">41</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#概念介绍"><span class="nav-number">1.</span> <span class="nav-text">概念介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Character-filter-字符过滤器"><span class="nav-number">1.1.</span> <span class="nav-text">Character filter(字符过滤器)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Tokenizer-分词器"><span class="nav-number">1.2.</span> <span class="nav-text">Tokenizer(分词器)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Token-filter-Token-过滤器"><span class="nav-number">1.3.</span> <span class="nav-text">Token filter(Token 过滤器)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Analyzer-分析器"><span class="nav-number">1.4.</span> <span class="nav-text">Analyzer(分析器)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Token-词元"><span class="nav-number">1.5.</span> <span class="nav-text">Token(词元)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Term"><span class="nav-number">1.6.</span> <span class="nav-text">Term</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Frequency-词频"><span class="nav-number">1.7.</span> <span class="nav-text">Frequency(词频)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#es内置-Character-filter"><span class="nav-number">2.</span> <span class="nav-text">es内置 Character filter</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#es内置tokenizer"><span class="nav-number">3.</span> <span class="nav-text">es内置tokenizer</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Standard-Tokenizer"><span class="nav-number">3.1.</span> <span class="nav-text">Standard Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Letter-Tokenizer"><span class="nav-number">3.2.</span> <span class="nav-text">Letter Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Lowercase-Tokenizer"><span class="nav-number">3.3.</span> <span class="nav-text">Lowercase Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Whitespace-Tokenizer"><span class="nav-number">3.4.</span> <span class="nav-text">Whitespace Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#UAX-URL-Email-Tokenizer"><span class="nav-number">3.5.</span> <span class="nav-text">UAX URL Email Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Classic-Tokenizer"><span class="nav-number">3.6.</span> <span class="nav-text">Classic Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Thai-Tokenizer"><span class="nav-number">3.7.</span> <span class="nav-text">Thai Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NGram-Tokenizer"><span class="nav-number">3.8.</span> <span class="nav-text">NGram Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Edge-NGram-Tokenizer"><span class="nav-number">3.9.</span> <span class="nav-text">Edge NGram Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keyword-Tokenizer"><span class="nav-number">3.10.</span> <span class="nav-text">Keyword Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pattern-Tokenizer"><span class="nav-number">3.11.</span> <span class="nav-text">Pattern Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Simple-Pattern-Tokenizer"><span class="nav-number">3.12.</span> <span class="nav-text">Simple Pattern Tokenizer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Simple-Pattern-Split-Tokenizer"><span class="nav-number">3.13.</span> <span class="nav-text">Simple Pattern Split Tokenizer</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">问问苑大宝</span>

  
</div>
<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>

<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>

-->


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  







<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    
      <style>
        a.gitment-editor-footer-tip { display: none; }
        .gitment-container.gitment-footer-container { display: none; }
      </style>
    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: 'Elasticsearch内置分词器及字符过滤器', 
            owner: 'yuanwenjian',
            repo: 'gitment-comments',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: '903e69fae75a4c67e11677d996fbf77c4a6f0639',
            
                client_id: '21bb0ade50d6f2c9707b'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    







  





  

  

  

  
  

  

  

  

  
  <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  
  
</body>
</html>
